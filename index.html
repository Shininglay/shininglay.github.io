<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Yu Liu (刘宇)</title>
    <meta name="author" content="Yu Liu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/robot.ico" type="image/x-icon">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400&family=Open+Sans:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
      :root {
        --primary-color: #122F51;
        --secondary-color: #3e6990;
        --accent-color: #1e88e5;
        --background-color: #ffffff;
        --text-color: #333333;
        --light-gray: #f5f5f5;
        --border-color: #e0e0e0;
      }

  
      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }
      
      body {
        font-family: 'Open Sans', sans-serif;
        line-height: 1.6;
        color: var(--text-color);
        background-color: var(--background-color);
        max-width: 1200px;
        margin: 0 auto;
        padding: 20px;
      }
      
      .container {
        width: 100%;
        max-width: 1000px;
        margin: 0 auto;
        padding: 30px 20px;
        background-color: var(--background-color);
        box-shadow: 0 5px 25px rgba(0, 0, 0, 0.05);
        border-radius: 8px;
      }
      
      /* Navigation Bar Styles */
      nav {
        width: 100%;
        background-color: var(--primary-color);
        padding: 12px 0;
        position: sticky;
        top: 0;
        z-index: 1000;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        margin-bottom: 20px;
        border-radius: 8px;
      }
      
      .nav-container {
        display: flex;
        justify-content: space-between;
        align-items: center;
        max-width: 1000px;
        margin: 0 auto;
        padding: 0 20px;
      }
      
      .logo {
        font-family: 'Lora', serif;
        font-size: 1.4rem;
        font-weight: 600;
        color: white;
        text-decoration: none;
      }
      
      .nav-links {
        display: flex;
        gap: 30px;
      }
      
      .nav-links a {
        color: white;
        text-decoration: none;
        font-weight: 500;
        transition: all 0.3s ease;
        padding: 5px 10px;
        border-radius: 4px;
      }
      
      .nav-links a:hover {
        background-color: rgba(255, 255, 255, 0.2);
        text-decoration: none;
      }
      
      .mobile-menu-btn {
        display: none;
        color: white;
        font-size: 1.5rem;
        background: none;
        border: none;
        cursor: pointer;
      }
      
      header {
        display: flex;
        flex-direction: column;
        align-items: center;
        margin-bottom: 40px;
        position: relative;
        padding-bottom: 30px;
      }
      
      .header-content {
        display: flex;
        width: 100%;
        gap: 40px;
        align-items: center;
        margin-top: 20px;
      }
      
      .profile-image {
        width: 230px;
        height: 230px;
        border-radius: 8px;
        object-fit: cover;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        transition: transform 0.3s ease;
      }
      
      .profile-image:hover {
        transform: scale(1.02);
      }
      
      .bio {
        flex: 1;
      }
      
      h1 {
        font-family: 'Lora', serif;
        font-size: 2.4rem;
        font-weight: 600;
        color: var(--primary-color);
        margin-bottom: 20px;
        letter-spacing: 0.5px;
        border-bottom: 2px solid var(--accent-color);
        padding-bottom: 10px;
        display: inline-block;
      }
      
      h2 {
        font-family: 'Lora', serif;
        font-size: 1.8rem;
        color: var(--primary-color);
        margin: 30px 0 20px 0;
        padding-bottom: 8px;
        border-bottom: 1px solid var(--border-color);
      }
      
      p {
        margin-bottom: 15px;
        line-height: 1.7;
        color: #444;
      }
      
      a {
        color: var(--accent-color);
        text-decoration: none;
        transition: color 0.2s;
      }
      
      a:hover {
        color: var(--secondary-color);
        text-decoration: underline;
      }
      
      .social-links {
        display: flex;
        gap: 20px;
        margin: 15px 0;
      }
      
      .social-links a {
        display: flex;
        align-items: center;
        gap: 5px;
        padding: 6px 15px;
        background-color: var(--light-gray);
        border-radius: 30px;
        font-weight: 500;
        font-size: 0.9rem;
        transition: all 0.2s;
      }
      
      .social-links a:hover {
        background-color: var(--primary-color);
        color: white;
        text-decoration: none;
        transform: translateY(-2px);
      }
      
      .social-links i {
        font-size: 1rem;
      }
      
      .research-item {
        display: flex;
        margin-bottom: 40px;
        padding-bottom: 30px;
        border-bottom: 1px solid var(--border-color);
        gap: 25px;
      }
      
      .research-item:last-child {
        border-bottom: none;
      }
      
      .research-image {
        width: 340px;
        min-width: 340px;
        border-radius: 6px;
        overflow: hidden;
        box-shadow: 0 3px 10px rgba(0, 0, 0, 0.1);
        display: flex;
        align-items: center;
        justify-content: center;
        background-color: #f9f9f9;
      }
      
      .research-image img {
        width: 100%;
        height: auto;
        object-fit: contain;
        transition: transform 0.3s ease;
      }
      
      .research-image img:hover {
        transform: scale(1.03);
      }
      
      .research-content {
        flex: 1;
      }
      
      .paper-title {
        font-family: 'Lora', serif;
        font-size: 1.3rem;
        font-weight: 600;
        color: var(--primary-color);
        margin-bottom: 10px;
        line-height: 1.4;
      }
      
      .authors {
        margin-bottom: 8px;
        font-size: 0.95rem;
        color: #555;
      }
      
      .publication {
        font-style: italic;
        margin-bottom: 15px;
        font-size: 0.95rem;
        color: #666;
      }
      
      .author-highlight {
        font-weight: 600;
        color: #444;
      }
      
      .hobby-section {
        text-align: center;
        margin: 40px 0;
        padding: 30px;
        background-color: var(--light-gray);
        border-radius: 8px;
      }
      
      .emoji-container {
        display: flex;
        flex-wrap: wrap;
        justify-content: center;
        gap: 15px;
        margin-top: 15px;
      }
      
      .emoji {
        font-size: 28px;
        background-color: white;
        width: 60px;
        height: 60px;
        display: flex;
        align-items: center;
        justify-content: center;
        border-radius: 50%;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        transition: transform 0.2s;
      }
      
      .emoji:hover {
        transform: scale(1.1);
      }
      
      .footer {
        text-align: center;
        margin-top: 50px;
        padding-top: 30px;
        border-top: 1px solid var(--border-color);
        font-size: 0.9rem;
        color: #777;
      }
      
      .contact-info {
        background-color: var(--light-gray);
        padding: 15px 20px;
        border-radius: 6px;
        margin-top: 15px;
      }
      
      .contact-info p {
        margin-bottom: 8px;
        display: flex;
        align-items: center;
        gap: 10px;
      }
      
      .contact-info i {
        color: var(--secondary-color);
        width: 20px;
      }
      
      .footnote {
        font-size: 0.9rem;
        color: #666;
        border-left: 3px solid var(--accent-color);
        padding-left: 15px;
        margin: 15px 0;
      }
      
      @media (max-width: 900px) {
        .nav-links {
          display: none;
          flex-direction: column;
          position: absolute;
          top: 100%;
          left: 0;
          right: 0;
          background-color: var(--primary-color);
          padding: 20px;
          gap: 15px;
          box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
        }
        
        .nav-links.show {
          display: flex;
        }
        
        .mobile-menu-btn {
          display: block;
        }
        
        .header-content {
          flex-direction: column;
          align-items: center;
          text-align: center;
        }
        
        .profile-image {
          margin-bottom: 25px;
        }
        
        .social-links {
          justify-content: center;
        }
        
        .research-item {
          flex-direction: column;
          align-items: center;
        }
        
        .research-image {
          width: 100%;
          max-width: 350px;
          min-width: unset;
          margin-bottom: 20px;
        }
      }
    </style>
  </head>

  <body>
    <nav>
      <div class="nav-container">
        <a href="#" class="logo">Yu Liu</a>
        <button class="mobile-menu-btn" id="mobileMenuBtn">
          <i class="fas fa-bars"></i>
        </button>
        <div class="nav-links" id="navLinks">
          <a href="#about">About</a>
          <a href="#research">Research</a>
          <a href="#hobby">Hobby</a>
          <a href="#photography">photography</a>
          <a href="#contact">Contact</a>
        </div>
      </div>
    </nav>

    
    <div class="container">
      <header id="about">
        <div class="header-content">
          <img src="images/Weikezhao.jpeg" alt="Weike Zhao" class="profile-image">
          <div class="bio">
            <h1>Yu Liu (刘宇)</h1>
            <p>I'm a PhD candidate at The University of Hongkong (HKU)</a>, 
            advised by Prof. Junzhi Liu</a>.</p>
<div style="margin-left: 20px; padding-right: 20px;">
    <p style="text-align: justify !important; text-align-last: left; line-height: 1.6; margin-bottom: 10px; margin-left: 0;">
        My research focuses on the <b>device-level applications</b> of novel organic materials, bridging the gap between material science and functional electronics, such as wearable sensors, organic transistors and memristors. 
    </p>

    <ul style="text-align: justify !important; text-align-last: left; line-height: 1.6; margin-left: 0; padding-left: 1.2em;">
        <li style="margin-bottom: 8px; word-break: break-word;">
            <b>Biomedical Diagnostics:</b> Developing early Alzheimer's disease detection devices based on chiral light.
        </li>
        <li style="word-break: break-word;">
            <b>Nano-Sensing:</b> Engineering ultrasensitive piezoresistive sensors using graphene nanoribbons.
        </li>
    </ul>
</div>
            
            <div class="contact-info" id="contact">
              <p><i class="fas fa-envelope"></i> zwk0629[at]sjtu.edu.cn</p>
              <!-- <p><i class="fab fa-weixin"></i> zhaoweike2000</p> -->
            </div>
            
            <div class="social-links">
              <a href="mailto:zwk0629@sjtu.edu.cn"><i class="fas fa-envelope"></i> Email</a>
              <a href="https://scholar.google.com/citations?user=yFSlxpwAAAAJ&hl=zh-CN&oi=ao"><i class="fas fa-graduation-cap"></i> Google Scholar</a>
              <a href="https://github.com/Angelakeke"><i class="fab fa-github"></i> GitHub</a>
            </div>
          </div>
        </div>
      </header>

      <section id="research">
        <h2>Research</h2>
        <div class="footnote">
          <sup>*</sup> denotes equal contribution, and <sup>†</sup> denotes corresponding author.
        </div>

        <div class="research-item">
          <div class="research-image">
            <img src="images/deeprare.png" alt="DeepRare">
          </div>
          <div class="research-content">
            <a href="https://www.nature.com/articles/s41586-025-10097-9">
              <div class="paper-title">An Agentic System for Rare Disease Diagnosis with Traceable Reasoning</div>
            </a>
            <div class="authors">
              <span class="author-highlight">Weike Zhao*</span>,
              <a href="https://chaoyi-wu.github.io/">Chaoyi Wu*</a>,
              <a>Yanjie Fan*</a>,
              <a href="https://xiaoman-zhang.github.io/">Xiaoman Zhang</a>,
              <a href="https://henrychur.github.io/">Pengcheng Qiu</a>,
              <a>Yuze Sun</a>,
              <a>Xiao Zhou</a>,
              <a>Yanfeng Wang</a>,
              <a href="https://annzhanglion.github.io/">Ya Zhang†</a>,
              <a href="https://www.shsmu.edu.cn/english/info/1285/2131.htm">Yongguo Yu†</a>,
              <a href="https://www.researchgate.net/profile/Kun-Sun-19">Kun Sun†</a>,
              <a href="https://weidixie.github.io/">Weidi Xie†</a>
            </div>
            <div class="publication">Nature (IF=48.5), 2026</div>
            <p>In this study, we introduce DeepRare, the first rare disease diagnosis agentic system powered by a large language model (LLM), capable of processing heterogeneous clinical inputs. </p>
          </div>
        </div>

        
        <div class="research-item">
          <div class="research-image">
            <img src="images/rag.png" alt="rag">
          </div>
          <div class="research-content">
            <a href="https://arxiv.org/pdf/2508.15746">
              <div class="paper-title">End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning</div>
            </a>
            <div class="authors">
              <a href="https://github.com/qiaoyu-zheng/">Qiaoyu Zheng</a>,
              <a>Yuze Sun</a>,
              <a href="https://chaoyi-wu.github.io/">Chaoyi Wu</a>,
              <span class="author-highlight">Weike Zhao</span>,
              <a href="https://henrychur.github.io/">Pengcheng Qiu</a>,
              <a href="https://www.shsmu.edu.cn/english/info/1285/2131.htm">Yongguo Yu</a>,
              <a href="https://www.researchgate.net/profile/Kun-Sun-19">Kun Sun</a>,
              <a>Yanfeng Wang</a>,
              <a href="https://annzhanglion.github.io/">Ya Zhang†</a>,
              <a href="https://weidixie.github.io/">Weidi Xie†</a>
            </div>
            <div class="publication">Major Revision at Nature Medicine (IF=50), 2026</div>
            <p>We introduce Deep-DxSearch, an end-to-end agentic RAG system trained with reinforcement learning for traceable diagnostic reasoning. Our framework addresses knowledge gaps and hallucinations in medical LLMs by constructing a large-scale medical retrieval corpus and using the LLM as a core agent with tailored rewards. Deep-DxSearch consistently outperforms prompt-engineering and training-free RAG approaches, achieving substantial gains over GPT-4o, DeepSeek-R1, and other medical frameworks for both common and rare disease diagnosis. </p>
          </div>
        </div>

        <div class="research-item">
          <div class="research-image">
            <img src="images/phenolip.png" alt="rag">
          </div>
          <div class="research-content">
            <a href="https://arxiv.org/abs/2602.06184">
              <div class="paper-title">PhenoLIP: Integrating Phenotype Ontology Knowledge into Medical Vision-Language Pretraining</div>
            </a>
            <div class="authors">
              <a>Cheng Liang</a>,
              <a href="https://chaoyi-wu.github.io/">Chaoyi Wu</a>,
              <span class="author-highlight">Weike Zhao</span>,
              <a href="https://annzhanglion.github.io/">Ya Zhang</a>,
              <a>Yanfeng Wang</a>,
              <a href="https://weidixie.github.io/">Weidi Xie†</a>
            </div>
            <div class="publication">Under Review at ECCV 2026</div>
            <p>We introduce PhenoLIP, a novel medical vision-language model that integrates structured phenotype knowledge to improve medical image analysis. It leverages PhenoKG, a new large-scale knowledge graph of over 520K image-text pairs linked to 3,000+ phenotypes. Evaluated on the PhenoBench benchmark, PhenoLIP significantly outperforms existing models, demonstrating the value of incorporating phenotype-centric knowledge. </p>
          </div>
        </div>

        <div class="research-item">
          <div class="research-image">
            <img src="images/MedRBench.jpeg" alt="MedRBench">
          </div>
          <div class="research-content">
            <a href="https://arxiv.org/pdf/2503.04691">
              <div class="paper-title">Quantifying the Reasoning Abilities of LLMs on Real-world Clinical Cases</div>
            </a>
            <div class="authors">
              <a href="https://henrychur.github.io/">Pengcheng Qiu*</a>,
              <a href="https://chaoyi-wu.github.io/">Chaoyi Wu*</a>,
              <a>Shuyu Liu</a>,
              <span class="author-highlight">Weike Zhao</span>,
              <a href="https://annzhanglion.github.io/">Ya Zhang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a>,
              <a href="https://weidixie.github.io/">Weidi Xie†</a>
            </div>
            <div class="publication">Nature Communication (IF=14.7), 2025</div>
            <p>In this study, we quantitatively evaluate the free-text reasoning abilities of various state-of-the-art LLMs, such as DeepSeek-R1 and OpenAI-o3-mini, in assessment recommendation, diagnostic decision, and treatment planning.</p>
          </div>
        </div>
        
        <div class="research-item">
          <div class="research-image">
            <img src="./RaTEScore/resources/model.png" alt="RaTEScore">
          </div>
          <div class="research-content">
            <a href="https://angelakeke.github.io/RaTEScore/">
              <div class="paper-title">RaTEScore: A Metric for Radiology Report Generation</div>
            </a>
            <div class="authors">
              <span class="author-highlight">Weike Zhao</span>,
              <a href="https://chaoyi-wu.github.io/">Chaoyi Wu</a>,
              <a href="https://xiaoman-zhang.github.io/">Xiaoman Zhang</a>,
              <a href="https://annzhanglion.github.io/">Ya Zhang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang†</a>,
              <a href="https://weidixie.github.io/">Weidi Xie†</a>
            </div>
            <div class="publication">EMNLP 2024 main paper</div>
            <p>RaTEScore is a novel, entity-aware metric to assess the quality of medical reports generated by AI models. It emphasizes crucial medical entities such as diagnostic outcomes and anatomical details, and is robust against complex medical synonyms and sensitive to negation expressions. The evaluations demonstrate that RaTEScore aligns more closely with human preference than existing metrics.</p>
          </div>
        </div>
        
        <div class="research-item">
          <div class="research-image">
            <img src="images/RP3D-Diag.png" alt="RP3D-Diag">
          </div>
          <div class="research-content">
            <a href="https://www.nature.com/articles/s41467-024-54424-6">
              <div class="paper-title">Large-scale Long-tailed Disease Diagnosis on Radiology Images</div>
            </a>
            <div class="authors">
              <a href="https://github.com/qiaoyu-zheng/">Qiaoyu Zheng*</a>,
              <span class="author-highlight">Weike Zhao*</span>,
              <a href="https://chaoyi-wu.github.io/">Chaoyi Wu*</a>,
              <a href="https://xiaoman-zhang.github.io/">Xiaoman Zhang</a>,
              <a href="https://annzhanglion.github.io/">Ya Zhang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang†</a>,
              <a href="https://weidixie.github.io/">Weidi Xie†</a>
            </div>
            <div class="publication">Nature Communication(IF=14.7), 2024</div>
            <p>In this paper, we build up an academically accessible, large-scale diagnostic dataset that encompasses 5568 disorders linked with 930 unique ICD-10-CM codes, containing 39,026 cases (192,675 scans). Also, we present a novel architecture that enables processing arbitrary number of input scans from various imaging modalities and initialize a new benchmark for multi-modal multi-anatomy long-tailed diagnosis.</p>
          </div>
        </div>
        
        <div class="research-item">
          <div class="research-image">
            <img src="images/GPT4V_eval.png" alt="GPT4V Evaluation">
          </div>
          <div class="research-content">
            <a href="https://drive.google.com/file/d/1kPDWgwpv8XlLu5sBuO2mRyylp0PDD6j5/view">
              <div class="paper-title">Can GPT-4V(ision) Serve Medical Applications? Case Studies on GPT-4V for Multimodal Medical Diagnosis</div>
            </a>
            <div class="authors">
              <a href="https://chaoyi-wu.github.io/">Chaoyi Wu*</a>,
              <a>Jiayu Lei*</a>,
              <a href="https://github.com/qiaoyu-zheng/">Qiaoyu Zheng*</a>,
              <span class="author-highlight">Weike Zhao*</span>,
              <a>Weixiong Lin*</a>,
              <a href="https://xiaoman-zhang.github.io/">Xiaoman Zhang*</a>,
              <a>Xiao Zhou*</a>,
              <a>Ziheng Zhao*</a>,
              <a href="https://annzhanglion.github.io/">Ya Zhang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a>,
              <a href="https://weidixie.github.io/">Weidi Xie†</a>
            </div>
            <div class="publication">Technical Report, 2023</div>
            <p>In this report, we evaluate GPT-4V for multimodal medical diagnosis at case studies, covering 17 human body systems, across 8 clinical imaging modalities. As the cases shown, GPT-4V is still far from clinical usage.</p>
          </div>
        </div>
      </section>

      <section id="hobby" class="hobby-section">
        <h2>Hobby</h2>
        <div class="emoji-container">
          <div class="emoji">&#9975;</div>
          <div class="emoji">&#127938;</div>
          <div class="emoji">&#9976;</div>
          <div class="emoji">&#127916;</div>
          <div class="emoji">&#127919;</div>
          <div class="emoji">&#127925;</div>
          <div class="emoji">&#127931;</div>
          <div class="emoji">&#127939;</div>
          <div class="emoji">&#127946;</div>
          <div class="emoji">&#127955;</div>
          <div class="emoji">&#127992;</div>
          <div class="emoji">&#128248;</div>
          <div class="emoji">&#129336;</div>
          <div class="emoji">&#127956;</div>
          <div class="emoji">&#9978;</div>
          <div class="emoji">&#127921;</div>
          <div class="emoji">&#127934;</div>
        </div>
      </section>

      <div id="clustrmaps">
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=h4YAqAN-BtgTi1jCWzvBvvs7JxONKNSiMa8xorgrfDk&co=3d95d3&cmn=f71111&cmo=ffc253'></script>
      </div>

      <div class="footer">
        <p>© 2026 Weike Zhao. Last updated: Feb 2026</p>
      </div>
    </div>

    <script>
      // Mobile menu toggle functionality
      document.getElementById('mobileMenuBtn').addEventListener('click', function() {
        document.getElementById('navLinks').classList.toggle('show');
      });
      
      // Close mobile menu when clicking on a link
      document.querySelectorAll('.nav-links a').forEach(link => {
        link.addEventListener('click', function() {
          document.getElementById('navLinks').classList.remove('show');
        });
      });
      
      // Smooth scrolling for navigation links
      document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener('click', function(e) {
          e.preventDefault();
          
          const targetId = this.getAttribute('href');
          if (targetId === '#') return;
          
          const targetElement = document.querySelector(targetId);
          if (targetElement) {
            window.scrollTo({
              top: targetElement.offsetTop - 80,
              behavior: 'smooth'
            });
          }
        });
      });
    </script>
  </body>
</html>
